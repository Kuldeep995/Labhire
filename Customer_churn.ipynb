{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Customer_churn",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kuldeep995/Labhire/blob/main/Customer_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r38zsexkrUE7"
      },
      "source": [
        "# **Problem Statement**\n",
        "\n",
        "### Given a customer profile, This model should be able to predict how likely they are to churn or how likely they are to leave."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxgyxIAOsA1-"
      },
      "source": [
        "# **Importing Necessary Libraries**\n",
        "\n",
        "\n",
        "\n",
        "The following code is written in Python 3.x. Libraries provide pre-written functionality to perform necessary tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9ApRTBvLVYN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7gP3CQ02z_i"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier ,RandomForestClassifier\n",
        "from xgboost import XGBClassifier \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score,roc_curve,accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xczvkaw-sfDQ"
      },
      "source": [
        "# **Data Loading and Cleaning**\n",
        "\n",
        "Load and Prepare dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwea0wGmaIBX",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "29e82872-4f27-4e61-ebb7-ff4e39a00d94"
      },
      "source": [
        "import io\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(io.BytesIO(uploaded['WA_Fn-UseC_-Telco-Customer-Churn.csv']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f61930cd-8e0e-4fbf-861c-e22c7f0b5472\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f61930cd-8e0e-4fbf-861c-e22c7f0b5472\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92EMng5oaqdA"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STh9vspXtD6W"
      },
      "source": [
        "# **Check Numeric and Categorical Features**\n",
        "\n",
        "Looking at the dataset, we can observe that the numerical values are represented as strings in some feature. Or the categorical values in some features might be represented as some other datatypes instead of strings. Hence it's good to check for the datatypes of all the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMMC2MJLbAMs"
      },
      "source": [
        "# IDENTIFYING NUMERICAL FEATURES\n",
        "numeric_data = df.select_dtypes(include=np.number) \n",
        "numeric_col = numeric_data.columns\n",
        "\n",
        "print(\"Numeric Features:\")\n",
        "print(numeric_data.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LamYEHzgcA9q"
      },
      "source": [
        "# IDENTIFYING CATEGORICAL FEATURES\n",
        "categorical_data = df.select_dtypes(exclude=np.number)\n",
        "categorical_col = categorical_data.columns\n",
        "\n",
        "print(\"Categorical Features:\")\n",
        "print(categorical_data.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTTf9gwet4CF"
      },
      "source": [
        "# **CHECK THE DATATYPES OF ALL COLUMNS.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yLjafscfI3P"
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3lpAGImuNx9"
      },
      "source": [
        "# **Data Preprocessing**\n",
        "\n",
        "\n",
        "\n",
        "*   Converting TotalChargees column to float.\n",
        "*   Attributing No internet service to No.\n",
        "*   Attributing No phone service to No.\n",
        "*   Attributing No phone service to No.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yXIPyBsfasN"
      },
      "source": [
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'],errors='coerce')\n",
        "df['TotalCharges']= df['TotalCharges'].astype(float)\n",
        "no_internet_feats = [ 'TechSupport','OnlineBackup', 'DeviceProtection','StreamingTV','OnlineSecurity','StreamingMovies']\n",
        "\n",
        "for i in no_internet_feats:\n",
        "  df[i] = df[i].replace({'No internet service':'No'})\n",
        "\n",
        "df['MultipleLines']=df['MultipleLines'].replace({'No phone service':'No'})\n",
        "df['SeniorCitizen']= df['SeniorCitizen'].replace({0:'No', 1:'Yes'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qG09GdPft-p"
      },
      "source": [
        "print(df.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZQEMbaKv7D4"
      },
      "source": [
        "# **Check for Class Imbalance**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEg6dXPacU6r"
      },
      "source": [
        "# we are finding the percentage of each class in the feature 'Churn'\n",
        "class_values = (df['Churn'].value_counts()/df['Churn'].value_counts().sum())*100\n",
        "print(class_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YYMZAIpwizz"
      },
      "source": [
        "# **Univariate analysis of Categorical columns**\n",
        "\n",
        "We using Bar plots to represent the frequency of all the values in the categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5WGtGGgco1G"
      },
      "source": [
        "# Selecting the categorical columns\n",
        "categorical_col = df.select_dtypes(include=['object']).columns\n",
        "plt.style.use('ggplot')\n",
        "for column in categorical_col:\n",
        "  if column == 'customerID':\n",
        "    continue\n",
        "  else:\n",
        "    plt.figure(figsize=(20,4))\n",
        "    plt.subplot(121)\n",
        "    df[column].value_counts().plot(kind='bar')\n",
        "    plt.title(column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NIY3v5lw9al"
      },
      "source": [
        "# **Univariate analysis of Continuous columns**\n",
        "\n",
        "We plot a histogram of all the continuous features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq_t5iA8c_Pj"
      },
      "source": [
        "numeric_col1 = df.select_dtypes(include=np.number).columns\n",
        "for column in numeric_col1:\n",
        "  plt.figure(figsize=(20,5))\n",
        "  plt.subplot(121)\n",
        "  sns.distplot(df[column])\n",
        "  plt.title(column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9YNjwqHxYkn"
      },
      "source": [
        "# **Bivariate Analysis**\n",
        "\n",
        "We plot every categorical feature against the target('Churn') by plotting a barchart.\n",
        "To understand the relationship between the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqACGtVks-0f"
      },
      "source": [
        "for column in categorical_col:\n",
        "  if column == 'customerID':\n",
        "    continue\n",
        "  else:\n",
        "    plt.figure(figsize=(20,4))\n",
        "    plt.subplot(121)\n",
        "    sns.countplot(x=df[column],hue=df['Churn'],data=df)\n",
        "    plt.title(column)    \n",
        "    plt.xticks(rotation=90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST60h1_b1Aft"
      },
      "source": [
        "*Imputing missing values with mean should not produce significant shift to the overall distribution*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSLR0Z9x7ptj"
      },
      "source": [
        "df['TotalCharges']=df['TotalCharges'].fillna(df['TotalCharges'].mode()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHTj2t1n1JkW"
      },
      "source": [
        "# **Function to Label Encode Categorical variables**\n",
        "\n",
        "In the code below we will perform label encoding on all the categorical features and also the target (since it is categorical) in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVjhi6aB47r4"
      },
      "source": [
        "df_c = df.copy()\n",
        "df_c = df_c.drop([\"customerID\"],axis =1)\n",
        "\n",
        "le = LabelEncoder()\n",
        "for feature in categorical_col:\n",
        "    try:\n",
        "        df_c[feature] = le.fit_transform(df_c[feature])\n",
        "    except:\n",
        "        print('Error encoding '+feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjoOR1dE1hcw"
      },
      "source": [
        "# **PREPARING THE TRAIN AND TEST DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zqhb0IruJcy"
      },
      "source": [
        "# Predictors\n",
        "X = df_c.iloc[:,:-1]\n",
        "# Target\n",
        "y = df_c.iloc[:,-1]\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrPqMTlj15MO"
      },
      "source": [
        "# **Applying Different Models at Data.**\n",
        "\n",
        "There are many Classification algorithms are present in machine learning, which are used for different classification applications. Some of the main classification algorithms are as follows that we use for our models:\n",
        "\n",
        "\n",
        "\n",
        "*   Logistic Regression\n",
        "*   Decision Tree\n",
        "*   Random Forest\n",
        "*   Gradient Boosting\n",
        "*   XGBoost\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S73aBD55t-s"
      },
      "source": [
        "#Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "y_scores = model.predict(x_test)\n",
        "auc = roc_auc_score(y_test, y_scores)\n",
        "acc = accuracy_score(y_test,y_scores)\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "y_scores_train = model.predict(x_train)\n",
        "train_acc = accuracy_score(y_train,y_scores_train)\n",
        "\n",
        "print('ROC_AUC_SCORE is',auc)\n",
        "print(\"---\"*10)\n",
        "print('Accuracy Score for the Test dataset:',acc)\n",
        "print('Accuracy Score for the Train dataset:',train_acc)\n",
        "print(\"---\"*10)\n",
        "print(\"The ROC_AUC PLOT: \")\n",
        "\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGGYp_yE8NV6"
      },
      "source": [
        "#Decision Tree Classifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "y_scores = model.predict(x_test)\n",
        "auc = roc_auc_score(y_test, y_scores)\n",
        "acc = accuracy_score(y_test,y_scores)\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "y_scores_train = model.predict(x_train)\n",
        "train_acc = accuracy_score(y_train,y_scores_train)\n",
        "\n",
        "print('ROC_AUC_SCORE is',auc)\n",
        "print(\"---\"*10)\n",
        "print('Accuracy Score for the Test dataset:',acc)\n",
        "print('Accuracy Score for the Train dataset:',train_acc)\n",
        "print(\"---\"*10)\n",
        "print(\"The ROC_AUC PLOT: \")\n",
        "\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZfR3nGC8RvD"
      },
      "source": [
        "#Random Forrest Classifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "y_scores = model.predict(x_test)\n",
        "auc = roc_auc_score(y_test, y_scores)\n",
        "acc = accuracy_score(y_test,y_scores)\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "y_scores_train = model.predict(x_train)\n",
        "train_acc = accuracy_score(y_train,y_scores_train)\n",
        "\n",
        "print('ROC_AUC_SCORE is',auc)\n",
        "print(\"---\"*10)\n",
        "print('Accuracy Score for the Test dataset:',acc)\n",
        "print('Accuracy Score for the Train dataset:',train_acc)\n",
        "print(\"---\"*10)\n",
        "print(\"The ROC_AUC PLOT: \")\n",
        "\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kNrJ8QMUXIQ"
      },
      "source": [
        "#Gradient Boosting Classifier\n",
        "model = GradientBoostingClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "y_scores = model.predict(x_test)\n",
        "auc = roc_auc_score(y_test, y_scores)\n",
        "acc = accuracy_score(y_test,y_scores)\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "y_scores_train = model.predict(x_train)\n",
        "train_acc = accuracy_score(y_train,y_scores_train)\n",
        "\n",
        "print('ROC_AUC_SCORE is',auc)\n",
        "print(\"---\"*10)\n",
        "print('Accuracy Score for the Test dataset:',acc)\n",
        "print('Accuracy Score for the Train dataset:',train_acc)\n",
        "print(\"---\"*10)\n",
        "print(\"The ROC_AUC PLOT: \")\n",
        "\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7foKqJdUlBk"
      },
      "source": [
        "#XGB Classifier\n",
        "model = XGBClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "y_scores = model.predict(x_test)\n",
        "auc = roc_auc_score(y_test, y_scores)\n",
        "acc = accuracy_score(y_test,y_scores)\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores)\n",
        "y_scores_train = model.predict(x_train)\n",
        "train_acc = accuracy_score(y_train,y_scores_train)\n",
        "\n",
        "print('ROC_AUC_SCORE is',auc)\n",
        "print(\"---\"*10)\n",
        "print('Accuracy Score for the Test dataset:',acc)\n",
        "print('Accuracy Score for the Train dataset:',train_acc)\n",
        "print(\"---\"*10)\n",
        "print(\"The ROC_AUC PLOT: \")\n",
        "\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC curve')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9y4NSq8WDk"
      },
      "source": [
        "# **Grid-Search & Hyperparameter Tuning**\n",
        "\n",
        "In the below task, we write a code that performs hyperparameter tuning for a random forest classifier. We have used the hyperparameters max_features, max_depth, criterion, n-estimators, min_sample_split and min_sample_leaf for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abfNpBQf813r"
      },
      "source": [
        "***Grid Search for Random Forest***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKbqdD2L8XV4",
        "outputId": "ac54cef2-e734-42bd-f381-6a9bb8e50df3"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3, random_state=42, stratify=y)\n",
        "rfc = RandomForestClassifier()\n",
        "param_grid = {'criterion' : ['entropy', 'gini'], 'max_depth' : [2, 4, 6, 8], 'n_estimators' : [300, 400, 500],'min_samples_split' : [2, 4, 6, 8], 'min_samples_leaf' : [2, 3, 5, 7]}\n",
        "grid_search_model = GridSearchCV(rfc, param_grid=param_grid, cv=3)\n",
        "grid_search_model.fit(x_train, y_train)\n",
        "print('Best Parameters are:',grid_search_model.best_params_)\n",
        "#print('Best score: ', grid_search_model.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-17b04256d38d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'criterion'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gini'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_depth'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_estimators'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'min_samples_split'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_samples_leaf'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrid_search_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgrid_search_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFcd0Cde87PW"
      },
      "source": [
        "***Applying the best parameters obtained using Grid Search on Random Forest model***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bLWixlr9xTB"
      },
      "source": [
        "We fit a random forest model using the best parameters obtained using Grid Search. Since the target is imbalanced, we apply Synthetic Minority Oversampling (SMOTE) for undersampling and oversampling the majority and minority classes in the target respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp-hNc1O95V7"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from yellowbrick.classifier import roc_auc\n",
        "\n",
        "# A function to use smote\n",
        "def grid_search_random_forest_best(dataframe,target):\n",
        "  x_train,x_test,y_train,y_test = train_test_split(dataframe,target, test_size=0.3, random_state=42)\n",
        "  # Applying Smote on train data for dealing with class imbalance\n",
        "  smote = SMOTE()\n",
        "  X_sm, y_sm =  smote.fit_sample(x_train, y_train)\n",
        "  # Intializing the Random Forrest Classifier\n",
        "  rfc = RandomForestClassifier(n_estimators = 300, criterion = 'gini', max_depth = 8, min_samples_split = 4, min_samples_leaf = 3)\n",
        "  rfc.fit(X_sm, y_sm)\n",
        "  y_pred = rfc.predict(x_test)\n",
        "  # Evaluation of result with the auc_roc graph\n",
        "  visualizer = roc_auc(rfc,x_test,y_test)\n",
        "  auc0 = roc_auc_score(y_test, y_pred)\n",
        "  acc = accuracy_score(y_test,y_pred)\n",
        "  print(\"Accuracy Score for the Test dataset:\",acc)\n",
        "  y_scores_train = model.predict(x_train)\n",
        "  train_acc = accuracy_score(y_train,y_scores_train)\n",
        "  print(\"Accuracy Score for the Train dataset:\",train_acc)\n",
        "grid_search_random_forest_best(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}